[
  {
    "objectID": "02examples/KF/021KFExample4.html",
    "href": "02examples/KF/021KFExample4.html",
    "title": "7  Example 4 - constant-velocity 2D motion tracking",
    "section": "",
    "text": "7.1 State-space model\nAssuming the above dynamics, and adding a noisy position measurement model, we obtain the linear state-space model\n\\[\n\\begin{align}\n  \\mathbf{x}_{k+1 } &= F  \\mathbf{x}_{k} + \\mathbf{q}_{k}, \\quad \\mathbf{q}_{k} \\sim \\mathcal{N} (0, Q), \\\\\n   \\mathbf{y}_{k+1 } &= H \\mathbf{x}_{k} + \\mathbf{r}_{k}, \\quad \\mathbf{r}_{k} \\sim \\mathcal{N} (0, R),\n\\end{align}\n\\]\nwith\n\\[\n  H = \\begin{bmatrix} 1 & 0 & 0 & 0\\\\  0 & 1 & 0 & 0 \\end{bmatrix}, \\quad\n  R = \\begin{bmatrix} \\sigma_1^2 & 0 \\\\  0 & \\sigma_2^2  \\end{bmatrix}  .\n\\]\nWe are now ready to simulate the Kalman filter.\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom scipy import linalg\n# we use Sarkka's utilities to streamline a bit...\nfrom common_utilities import generate_ssm, RandomState, rmse, plot_car_trajectory\n# initialize\nq = 1.    # process noise\ndt = 0.1  # time step\ns = 0.5   # measurement noise\n\nM = 4  # State dimension\nN = 2  # Observation dimension\n\nA = np.array([[1, 0, dt, 0],\n              [0, 1, 0, dt],\n              [0, 0, 1, 0],\n              [0, 0, 0, 1]])\n\nQ = q * np.array([[dt ** 3 / 3, 0, dt ** 2 / 2, 0],\n                  [0, dt **3 / 3, 0, dt ** 2 / 2],\n                  [dt ** 2 / 2, 0, dt, 0],\n                  [0, dt ** 2 / 2, 0, dt]])\n\nH = np.array([[1, 0, 0, 0],\n              [0, 1, 0, 0]])\n\nR = np.array([[s ** 2, 0],\n              [0, s ** 2]])\n\nx_0 = np.array([0., 0., 1., -1.])\n# Simulate trajectory and noisy measurements\nrandom_state = RandomState(6)\nsteps = 100\n\nstates, observations = generate_ssm(x_0, A, Q, H, R, steps, random_state)\n\nplot_car_trajectory(observations, states, \"Trajectory\")",
    "crumbs": [
      "Kalman Filters",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Example 4 - constant-velocity 2D motion tracking</span>"
    ]
  },
  {
    "objectID": "02examples/KF/021KFExample4.html#state-space-model",
    "href": "02examples/KF/021KFExample4.html#state-space-model",
    "title": "7  Example 4 - constant-velocity 2D motion tracking",
    "section": "",
    "text": "definition of all parameters\ninitilization of all matrices\nsimulation and generate noisy measurements - plot\nKalman filter\nKalman smoother",
    "crumbs": [
      "Kalman Filters",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Example 4 - constant-velocity 2D motion tracking</span>"
    ]
  },
  {
    "objectID": "02examples/KF/021KFExample4.html#kalman-filter",
    "href": "02examples/KF/021KFExample4.html#kalman-filter",
    "title": "7  Example 4 - constant-velocity 2D motion tracking",
    "section": "7.2 Kalman filter",
    "text": "7.2 Kalman filter\n\ndef kalman_filter(m_0, P_0, A, Q, H, R, observations):\n    M = m_0.shape[-1]\n    steps, N = observations.shape\n    \n    kf_m = np.empty((steps, M))\n    kf_P = np.empty((steps, M, M))\n    \n    m = m_0\n    P = P_0\n    \n    for i in range(steps):\n        y = observations[i]\n        m = A @ m\n        P = A @ P @ A.T + Q\n        \n        S = H @ P @ H.T + R\n        # More efficient and stable way of computing K = P @ H.T @ linalg.inv(S)\n        # This also leverages the fact that S is known to be a positive definite matrix (assume_a=\"pos\")\n        K = linalg.solve(S.T, H @ P, assume_a=\"pos\").T \n        \n        m = m + K @ (y - H @ m)\n        P = P - K @ S @ K.T\n        \n        kf_m[i] = m\n        kf_P[i] = P\n    return kf_m, kf_P\n\n\nm_0 = x_0\nP_0 = np.array([[1, 0, 0, 0],\n                [0, 1, 0, 0],\n                [0, 0, 1, 0],\n                [0, 0, 0, 1]])\n\nkf_m, kf_P = kalman_filter(m_0, P_0, A, Q, H, R, observations)\n\nplot_car_trajectory(observations, states, \"Trajectory\", kf_m, \"Filter Estimate\")\n\nrmse_raw = rmse(states[:, :2], observations)\nrmse_kf = rmse(kf_m[:, :2], states[:, :2])\nprint(f\"RAW RMSE: {rmse_raw}\")\nprint(f\"KF RMSE: {rmse_kf}\")\n\nRAW RMSE: 0.7131995943918173\nKF RMSE: 0.3746597043548562",
    "crumbs": [
      "Kalman Filters",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Example 4 - constant-velocity 2D motion tracking</span>"
    ]
  },
  {
    "objectID": "02examples/KF/021KFExample4.html#kalman-smoother",
    "href": "02examples/KF/021KFExample4.html#kalman-smoother",
    "title": "7  Example 4 - constant-velocity 2D motion tracking",
    "section": "7.3 Kalman smoother",
    "text": "7.3 Kalman smoother\nThe RTS smoother requires a forward run of the Kalman filter that provides the state and the covariance matrix, for all time steps.\n\ndef rts_smoother(kf_m, kf_P, A, Q):\n    steps, M = kf_m.shape\n    \n    rts_m = np.empty((steps, M))\n    rts_P = np.empty((steps, M, M))\n    \n    m = kf_m[-1]\n    P = kf_P[-1]\n    \n    rts_m[-1] = m\n    rts_P[-1] = P\n    \n    for i in range(steps-2, -1, -1):\n        filtered_m = kf_m[i]\n        filtered_P = kf_P[i]\n        \n        mp = A @ filtered_m\n        Pp = A @ filtered_P @ A.T + Q\n\n        # More efficient and stable way of computing Gk = filtered_P @ A.T @ linalg.inv(Pp)\n        # This also leverages the fact that Pp is known to be a positive definite matrix (assume_a=\"pos\")\n        Gk = linalg.solve(Pp, A @ filtered_P, assume_a=\"pos\").T \n\n        m = filtered_m + Gk @ (m - mp)\n        P = filtered_P + Gk @ (P - Pp) @ Gk.T\n        \n        rts_m[i] = m\n        rts_P[i] = P\n\n    return rts_m, rts_P\n\n\nrts_m, rts_P = rts_smoother(kf_m, kf_P, A, Q)\n\nplot_car_trajectory(observations, states, \"Trajectory\", rts_m, \"Smoother Estimate\")\n\nrmse_rts = rmse(states[:, :2], rts_m[:, :2])\n\nprint(f\"RAW RMSE: {rmse_raw}\")\nprint(f\"KF RMSE: {rmse_kf}\")\nprint(f\"RTS RMSE: {rmse_rts}\")\n\nRAW RMSE: 0.7131995943918173\nKF RMSE: 0.3746597043548562\nRTS RMSE: 0.1857332232186917",
    "crumbs": [
      "Kalman Filters",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Example 4 - constant-velocity 2D motion tracking</span>"
    ]
  },
  {
    "objectID": "02examples/KF/021KFExample4.html#conclusions-on-kalman-filters",
    "href": "02examples/KF/021KFExample4.html#conclusions-on-kalman-filters",
    "title": "7  Example 4 - constant-velocity 2D motion tracking",
    "section": "7.4 Conclusions on Kalman Filters",
    "text": "7.4 Conclusions on Kalman Filters\n\nworkhorse for all linear, Gaussian problems\ncases covered here:\n\ntrack a constant\ntrack a random walk\nmovement tracking: scalar consatnt velocity, 2D and 3D tracking\n\n2 basic philosophies:\n\nuse a KF classs\ninclude KF code each time\nuse KF module/function\n\nChoice: I prefer (2). Since the KF is coded in only 5 lines, there is no real need for a class and the resulting code remains very readable\nProcess noise modelling, to design the matrix \\(Q,\\) is a complex subject. See Saho and references therein.",
    "crumbs": [
      "Kalman Filters",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Example 4 - constant-velocity 2D motion tracking</span>"
    ]
  },
  {
    "objectID": "02examples/KF/021KFExample4.html#references",
    "href": "02examples/KF/021KFExample4.html#references",
    "title": "7  Example 4 - constant-velocity 2D motion tracking",
    "section": "7.5 References",
    "text": "7.5 References\n\n K. Law, A Stuart, K. Zygalakis. Data Assimilation. A Mathematical Introduction. Springer. 2015.\n M. Asch, M. Bocquet, M. Nodet. Data Assimilation: Methods, Algorithms and Applications. SIAM. 2016.\n M. Asch. A Toobox for Digital Twins. From Model-Based to Data-Driven. SIAM. 2022\n S. Sarkka, L. Svensson. Bayesian Filtering and Smoothing, 2nd ed., Cambridge University Press. 2023.",
    "crumbs": [
      "Kalman Filters",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Example 4 - constant-velocity 2D motion tracking</span>"
    ]
  },
  {
    "objectID": "01theory/022NlinKF.html",
    "href": "01theory/022NlinKF.html",
    "title": "8  Nonlinear Kalman Filters",
    "section": "",
    "text": "8.1 Introduction\nRecall that the Kalman filter can be used for\nKalman filters are linear (and Gaussian) or nonlinear. Here we will formulate the basic nonliner filter, known as the extended Kalman filter.",
    "crumbs": [
      "Nonlinear Kalman Filters",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Nonlinear Kalman Filters</span>"
    ]
  },
  {
    "objectID": "01theory/022NlinKF.html#introduction",
    "href": "01theory/022NlinKF.html#introduction",
    "title": "8  Nonlinear Kalman Filters",
    "section": "",
    "text": "state estimation—this is the direct filtering (or smoothing) problem\nparameter estimation—this is the inverse problem based on filtering with a pseudo-time",
    "crumbs": [
      "Nonlinear Kalman Filters",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Nonlinear Kalman Filters</span>"
    ]
  },
  {
    "objectID": "01theory/022NlinKF.html#recall-kalman-filter-problem---general-formulation",
    "href": "01theory/022NlinKF.html#recall-kalman-filter-problem---general-formulation",
    "title": "8  Nonlinear Kalman Filters",
    "section": "8.2 Recall: Kalman filter problem - general formulation",
    "text": "8.2 Recall: Kalman filter problem - general formulation\nWe present a very general formulation that will later be convenient for joint state and parameter estimation problems. Consider a discrete-time nonlinear dynamical system with noisy state transitions and noisy observations that are also noinlinear.\n\nDynamics:\n\\[\\quad v_{j+1} = \\Psi(v_j) + \\xi_j, \\quad j \\in \\mathbb{Z}^+ \\]\nObservations:\n\\[y_{j+1} = h (v_{j+1}) + \\eta_{j+1}, \\quad j \\in \\mathbb{Z}^+ \\]\nProbability (densities):\n\\[v_0 \\sim \\mathcal{N}(m_0,C_0), \\quad \\xi_j \\sim \\mathcal{N}(0,\\Sigma),  \\quad \\eta_j \\sim \\mathcal{N}(0,\\Gamma)\\]\nProbability (independence):\n\\[v_0 \\perp {\\xi_j} \\perp {\\eta_j}\\]\nOperators:\n\\[\\begin{eqnarray}\n    \\Psi \\colon \\mathcal{H}_s &\\mapsto \\mathcal{H}_s, \\\\\n    h  \\colon \\mathcal{H}_s &\\mapsto \\mathcal{H}_o,\n   \\end{eqnarray}\\] where \\(v_j \\in \\mathcal{H}_s,\\) \\(y_j \\in \\mathcal{H}_o\\) and \\(\\mathcal{H}\\) is a finite-dimensional Hilbert space.\n\nFiltering problem:\nEstimate (optimally) the state \\(v_j\\) of the dynamical system at time \\(j,\\) given the data \\(Y_j = \\{y_i\\}_{i=1}^{j}\\) up to time \\(j.\\) This is achieved by using a two-step predictor-corrector method. We will use the more general notation of (Law, Stuart, and Zygalakis 2015) instead of the usual, classical state-space formulation that is used in (Asch, Bocquet, and Nodet 2016) and (Asch 2022).\nThe objective here is to update the filtering distribution \\(\\mathbb{P}(v_j \\vert Y_j),\\) from time \\(j\\) to time \\(j+1,\\) in the nonlinear, Gaussian case, where\n\n\\(\\Psi\\) and \\(h\\) are nonlinear functions,\nall distributions are Gaussian.\n\nSuppose the Jacobian matrices of \\(\\Psi\\) and \\(h\\) exist, and are denoted by\n\\[\n\\begin{eqnarray}\n   \\Psi_x(v) &= \\left[ \\frac{\\partial \\Psi}{\\partial x} \\right]_{x=m}\\\\\n   h_x(v)    &= \\left[ \\frac{\\partial h}{\\partial x} \\right]_{x=m}.\n\\end{eqnarray}\n\\]\n\nLet \\((m_j, C_j)\\) denote the mean and covariance of \\(v_j \\vert Y_j\\) and note that these entirely characterize the random variable since it is Gaussian.\nLet \\((\\hat{m}_{j+1}, \\hat{C}_{j+1})\\) denote the mean and covariance of \\(v_{j+1} \\vert Y_j\\) and note that these entirely characterize the random variable since it is Gaussian.\nDerive the map \\((m_j, C_j) \\mapsto (m_{j+1}, C_{j+1})\\) using the previous step.\n\n\n8.2.1 Prediction/Forecast\n\\[ \\mathbb{P}(v_n \\vert y_1, \\ldots, y_n) \\mapsto \\mathbb{P}(v_{n+1} \\vert y_1, \\ldots, y_n) \\]\n\nP0: initialize \\((m_0, C_0)\\) and compute \\(v_0\\)\nP1: predict the state, measurement\n\\[\n   \\begin{align}\n   v_{j+1} &= \\Psi (v_j) + \\xi_j \\\\\n   y_{j+1} &= h (v_{j+1}) + \\eta_{j+1}\n   \\end{align}\n   \\]\nP2: predict the mean and covariance\n\\[\n   \\begin{align}\n   \\hat{m}_{j+1}  &= \\Psi (m_j) \\\\\n   \\hat{C}_{j+1}  &= \\Psi_x C_j \\Psi_x^{\\mathrm{T}} + \\Sigma\n   \\end{align}\n   \\]\n\n\n\n8.2.2 Correction/Analysis\n\\[ \\mathbb{P}(v_{n+1} \\vert y_1, \\ldots, y_n) \\mapsto \\mathbb{P}(v_{n+1} \\vert y_1, \\ldots, y_{n+1}) \\]\n\nC1: compute the innovation\n\\[ d_{j+1} = y_{j+1} - h (\\hat{m}_{j+1}) \\]\nC2: compute the measurement covariance\n\\[ S_{j+1} = h_x \\hat{C}_{j+1}  h_x^{\\mathrm{T}} + \\Gamma \\]\nC3: compute the (optimal) Kalman gain\n\\[ K_{j+1} = \\hat{C}_{j+1} h_x^{\\mathrm{T}}  S_{j+1}^{-1} \\]\nC4: update/correct the mean and covariance\n\\[\n   \\begin{align}\n   {m}_{j+1}  &= \\hat{m}_{j+1} + K_{j+1} d_{j+1}, \\\\\n   {C}_{j+1}  &= \\hat{C}_{j+1} - K_{j+1}  S_{j+1}  K_{j+1}^{\\mathrm{T}}.\n   \\end{align}\n   \\]\n\n\n\n8.2.3 Loop over time\n\nset \\(j = j+1\\)\ngo to step P1",
    "crumbs": [
      "Nonlinear Kalman Filters",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Nonlinear Kalman Filters</span>"
    ]
  },
  {
    "objectID": "01theory/022NlinKF.html#state-space-formulation",
    "href": "01theory/022NlinKF.html#state-space-formulation",
    "title": "8  Nonlinear Kalman Filters",
    "section": "8.3 State-space formulation",
    "text": "8.3 State-space formulation\nIn classical filter theory, a state space formulation is usually used.\n\\[\n\\begin{eqnarray}\n&& x_{k+1}  = f (x_k)  + w_k \\\\\n&& y_{k+1}  = h (x_k) + v_k,\n\\end{eqnarray}\n\\]\nwhere \\(f\\) and \\(h\\) are nonlinear, differentiable functions with Jacobian matrices \\(D_f\\) and \\(D_h\\) respectively, \\(w_k \\sim \\mathcal{N}(0,Q),\\) \\(v_k \\sim \\mathcal{N}(0,R).\\)\nThe 2-step filter:\n\n8.3.1 Initialization\n\\[ x_0, \\quad P_0 \\]\n\n\n8.3.2 1. Prediction\n\\[\n\\begin{eqnarray}\n&& x_{k+1}^- = f (x_k) \\\\\n&& P_{k+1}^- = D_f P_k D_f^{\\mathrm{T}} + Q\n\\end{eqnarray}\n\\]\n\n\n8.3.3 2. Correction\n\\[\n\\begin{eqnarray}\n  K_{k+1} && = P_{k+1}^{-} D_h^{\\mathrm{T}} ( D_h  P_{k+1}^{-} D_h^{\\mathrm{T}} + R )^{-1}\n                 \\quad (= P_{k+1}^- D_h^{\\mathrm{T}} S^{-1}) \\\\\n  x_{k+1} &&= x_{k+1}^{-} + K_{k+1} (y_{k+1} - h (x_{k+1}^-) ) \\\\\n  P_{k+1} &&= (I -  K_{k+1} D_h ) P_{k+1}^-\n            \\quad (= P_{k+1}^- - K_{k+1} S K^{\\mathrm{T}}_{k+1})\n\\end{eqnarray}\n\\]\n\n\n8.3.4 Loop\nSet \\(k = k+1\\) and go to step 1.",
    "crumbs": [
      "Nonlinear Kalman Filters",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Nonlinear Kalman Filters</span>"
    ]
  },
  {
    "objectID": "01theory/022NlinKF.html#other-nonlinear-filters",
    "href": "01theory/022NlinKF.html#other-nonlinear-filters",
    "title": "8  Nonlinear Kalman Filters",
    "section": "8.4 Other nonlinear filters",
    "text": "8.4 Other nonlinear filters\n\nunscented Kalman filter\nparticle filter\n\nFor details, please consult the references.\n\n\n\n\nAsch, Mark. 2022. A Toolbox for Digital Twins: From Model-Based to Data-Driven. Philadelphia, PA: Society for Industrial; Applied Mathematics. https://doi.org/10.1137/1.9781611976977.\n\n\nAsch, Mark, Marc Bocquet, and Maëlle Nodet. 2016. Data Assimilation: Methods, Algorithms, and Applications. Philadelphia, PA: Society for Industrial; Applied Mathematics. https://doi.org/10.1137/1.9781611974546.\n\n\nLaw, Kody, Andrew Stuart, and Konstantinos Zygalakis. 2015. Data Assimilation: A Mathematical Introduction. Vol. 62. Texts in Applied Mathematics. Cham: Springer International Publishing. https://doi.org/10.1007/978-3-319-20325-6.",
    "crumbs": [
      "Nonlinear Kalman Filters",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Nonlinear Kalman Filters</span>"
    ]
  }
]