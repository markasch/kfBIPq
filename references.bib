@book{Asch2016,
	address = {Philadelphia, PA},
	title = {Data {Assimilation}: {Methods}, {Algorithms}, and {Applications}},
	isbn = {978-1-61197-453-9 978-1-61197-454-6},
	shorttitle = {Data {Assimilation}},
	url = {http://epubs.siam.org/doi/book/10.1137/1.9781611974546},
	language = {en},
	urldate = {2024-01-03},
	publisher = {Society for Industrial and Applied Mathematics},
	author = {Asch, Mark and Bocquet, Marc and Nodet, Maëlle},
	month = dec,
	year = {2016},
	doi = {10.1137/1.9781611974546},
	file = {Available Version (via Google Scholar):/Users/markasch/Zotero/storage/63X2LMER/Asch et al. - 2016 - Data Assimilation Methods, Algorithms, and Applic.pdf:application/pdf},
}

@book{Asch2022,
	address = {Philadelphia, PA},
	title = {A {Toolbox} for {Digital} {Twins}: {From} {Model}-{Based} to {Data}-{Driven}},
	isbn = {978-1-61197-696-0 978-1-61197-697-7},
	shorttitle = {A {Toolbox} for {Digital} {Twins}},
	url = {https://epubs.siam.org/doi/book/10.1137/1.9781611976977},
	language = {en},
	urldate = {2024-01-03},
	publisher = {Society for Industrial and Applied Mathematics},
	author = {Asch, Mark},
	month = jan,
	year = {2022},
	doi = {10.1137/1.9781611976977},
	file = {Available Version (via Google Scholar):/Users/markasch/Zotero/storage/I9SHUNXY/Asch - 2022 - A Toolbox for Digital Twins From Model-Based to D.pdf:application/pdf},
}

@book{Sarkka2023,
  author    = {S{\"a}rkk{\"a}, S. and Svensson, L.},
  publisher = {Cambridge University Press},
  title     = {Bayesian Filtering and Smoothing},
  year      = {2023},
  series    ={Institute of Mathematical Statistics Textbooks},
  doi       ={10.1017/9781108917407},
  edition   ={2},
}

@book{LSZ2015,
	address = {Cham},
	series = {Texts in {Applied} {Mathematics}},
	title = {Data {Assimilation}: {A} {Mathematical} {Introduction}},
	volume = {62},
	isbn = {978-3-319-20324-9 978-3-319-20325-6},
	shorttitle = {Data {Assimilation}},
	url = {https://link.springer.com/10.1007/978-3-319-20325-6},
	language = {en},
	urldate = {2024-02-29},
	publisher = {Springer International Publishing},
	author = {Law, Kody and Stuart, Andrew and Zygalakis, Konstantinos},
	year = {2015},
	doi = {10.1007/978-3-319-20325-6},
	file = {Law et al. - 2015 - Data Assimilation A Mathematical Introduction.pdf:/Users/markasch/Zotero/storage/KD4VDZAD/Law et al. - 2015 - Data Assimilation A Mathematical Introduction.pdf:application/pdf},
}

@book{ReichCotter2015,
 place={Cambridge},
 title={Probabilistic Forecasting and Bayesian Data Assimilation},
 publisher={Cambridge University Press}, 
 author={Reich, Sebastian and Cotter, Colin}, 
 year={2015}} 

@article{Huang2022,
doi = {10.1088/1361-6420/ac99fa},
url = {https://dx.doi.org/10.1088/1361-6420/ac99fa},
year = {2022},
month = {oct},
publisher = {IOP Publishing},
volume = {38},
number = {12},
pages = {125006},
author = {Daniel Zhengyu Huang and Jiaoyang Huang and Sebastian Reich and Andrew M Stuart},
title = {Efficient derivative-free Bayesian inference for large-scale inverse problems},
journal = {Inverse Problems},
abstract = {We consider Bayesian inference for large-scale inverse problems, where computational challenges arise from the need for repeated evaluations of an expensive forward model. This renders most Markov chain Monte Carlo approaches infeasible, since they typically require  model runs, or more. Moreover, the forward model is often given as a black box or is impractical to differentiate. Therefore derivative-free algorithms are highly desirable. We propose a framework, which is built on Kalman methodology, to efficiently perform Bayesian inference in such inverse problems. The basic method is based on an approximation of the filtering distribution of a novel mean-field dynamical system, into which the inverse problem is embedded as an observation operator. Theoretical properties are established for linear inverse problems, demonstrating that the desired Bayesian posterior is given by the steady state of the law of the filtering distribution of the mean-field dynamical system, and proving exponential convergence to it. This suggests that, for nonlinear problems which are close to Gaussian, sequentially computing this law provides the basis for efficient iterative methods to approximate the Bayesian posterior. Ensemble methods are applied to obtain interacting particle system approximations of the filtering distribution of the mean-field model; and practical strategies to further reduce the computational and memory cost of the methodology are presented, including low-rank approximation and a bi-fidelity approach. The effectiveness of the framework is demonstrated in several numerical experiments, including proof-of-concept linear/nonlinear examples and two large-scale applications: learning of permeability parameters in subsurface flow; and learning subgrid-scale parameters in a global climate model. Moreover, the stochastic ensemble Kalman filter and various ensemble square-root Kalman filters are all employed and are compared numerically. The results demonstrate that the proposed method, based on exponential convergence to the filtering distribution of a mean-field dynamical system, is competitive with pre-existing Kalman-based methods for inverse problems.}
}



@incollection{Stuart2015,
	address = {Cham},
	title = {The {Bayesian} {Approach} to {Inverse} {Problems}},
	isbn = {978-3-319-11259-6},
	url = {https://link.springer.com/10.1007/978-3-319-11259-6_7-1},
	abstract = {These lecture notes highlight the mathematical and computational structure relating to the formulation of, and development of algorithms for, the Bayesian approach to inverse problems in differential equations. This approach is fundamental in the quantiﬁcation of uncertainty within applications involving the blending of mathematical models with data. The ﬁnite-dimensional situation is described ﬁrst, along with some motivational examples. Then the development of probability measures on separable Banach space is undertaken, using a random series over an inﬁnite set of functions to construct draws; these probability measures are used as priors in the Bayesian approach to inverse problems. Regularity of draws from the priors is studied in the natural Sobolev or Besov spaces implied by the choice of functions in the random series construction, and the Kolmogorov continuity theorem is used to extend regularity considerations to the space of Hölder continuous functions. Bayes’ theorem is derived in this prior setting, and here interpreted as ﬁnding conditions under which the posterior is absolutely continuous with respect to the prior, and determining a formula for the Radon-Nikodym derivative in terms of the likelihood of the data. Having established the form of the posterior, we then describe various properties common to it in the inﬁnite-dimensional setting. These properties include well-posedness, approximation theory, and the existence of maximum a posteriori estimators. We then describe measure-preserving dynamics, again on the inﬁnite-dimensional space, including Markov chain Monte Carlo and sequential Monte Carlo methods, and measure-preserving reversible stochastic differential equations. By formulating the theory and algorithms on the underlying inﬁnite-dimensional space, we obtain a framework suitable for rigorous analysis of the accuracy of reconstructions, of computational complexity, as well as naturally constructing algorithms which perform well under mesh reﬁnement, since they are inherently well deﬁned in inﬁnite dimensions.},
	language = {en},
	urldate = {2024-01-08},
	booktitle = {Handbook of {Uncertainty} {Quantification}},
	publisher = {Springer International Publishing},
	author = {Dashti, Masoumeh and Stuart, Andrew M.},
	editor = {Ghanem, Roger and Higdon, David and Owhadi, Houman},
	year = {2015},
	doi = {10.1007/978-3-319-11259-6_7-1},
	keywords = {Inverse Problem, BIP, Bayes},
	pages = {1--118},
	file = {Dashti and Stuart - 2015 - The Bayesian Approach to Inverse Problems.pdf:/Users/markasch/Zotero/storage/BNJ6LD8D/Dashti and Stuart - 2015 - The Bayesian Approach to Inverse Problems.pdf:application/pdf},
}


@article{Stuart2013,
	title = {Ensemble {Kalman} methods for inverse problems},
	volume = {29},
	issn = {0266-5611, 1361-6420},
	url = {https://iopscience.iop.org/article/10.1088/0266-5611/29/4/045001},
	doi = {10.1088/0266-5611/29/4/045001},
	abstract = {The ensemble Kalman ﬁlter (EnKF) was introduced by Evensen in 1994 (Evensen 1994 J. Geophys. Res. 99 10143–62) as a novel method for data assimilation: state estimation for noisily observed time-dependent problems. Since that time it has had enormous impact in many application domains because of its robustness and ease of implementation, and numerical evidence of its accuracy. In this paper we propose the application of an iterative ensemble Kalman method for the solution of a wide class of inverse problems. In this context we show that the estimate of the unknown function that we obtain with the ensemble Kalman method lies in a subspace A spanned by the initial ensemble. Hence the resulting error may be bounded above by the error found from the best approximation in this subspace. We provide numerical experiments which compare the error incurred by the ensemble Kalman method for inverse problems with the error of the best approximation in A, and with variants on traditional least-squares approaches, restricted to the subspace A. In so doing we demonstrate that the ensemble Kalman method for inverse problems provides a derivative-free optimization method with comparable accuracy to that achieved by traditional least-squares approaches. Furthermore, we also demonstrate that the accuracy is of the same order of magnitude as that achieved by the best approximation. Three examples are used to demonstrate these assertions: inversion of a compact linear operator; inversion of piezometric head to determine hydraulic conductivity in a Darcy model of groundwater ﬂow; and inversion of Eulerian velocity measurements at positive times to determine the initial condition in an incompressible ﬂuid.},
	language = {en},
	number = {4},
	urldate = {2024-01-03},
	journal = {Inverse Problems},
	author = {Iglesias, Marco A and Law, Kody J H and Stuart, Andrew M},
	month = apr,
	year = {2013},
	keywords = {EnKF, EKI},
	pages = {045001},
	file = {Iglesias et al. - 2013 - Ensemble Kalman methods for inverse problems.pdf:/Users/markasch/Zotero/storage/GMPYK7JW/Iglesias et al. - 2013 - Ensemble Kalman methods for inverse problems.pdf:application/pdf},
}

@misc{Stuart2022,
	title = {Ensemble {Kalman} {Methods}: {A} {Mean} {Field} {Perspective}},
	shorttitle = {Ensemble {Kalman} {Methods}},
	url = {http://arxiv.org/abs/2209.11371},
	abstract = {This paper provides a unifying mean ﬁeld based framework for the derivation and analysis of ensemble Kalman methods. Both state estimation and parameter estimation problems are considered, and formulations in both discrete and continuous time are employed. For state estimation problems both the control and ﬁltering approaches are studied; analogously, for parameter estimation (inverse) problems the optimization and Bayesian perspectives are both studied. The approach taken uniﬁes a wide-ranging literature in the ﬁeld, provides a framework for analysis of ensemble Kalman methods, and suggests open problems.},
	language = {en},
	urldate = {2024-01-03},
	publisher = {arXiv (to appear in Acta Numerica 2025)},
	author = {Calvello, Edoardo and Reich, Sebastian and Stuart, Andrew M.},
	month = sep,
	year = {2022},
	note = {arXiv:2209.11371 [cs, math]},
	keywords = {Mathematics - Numerical Analysis, Mathematics - Optimization and Control, EnKF, EKI, mean field},
	file = {Calvello et al. - 2022 - Ensemble Kalman Methods A Mean Field Perspective.pdf:/Users/markasch/Zotero/storage/HB5SG9SH/Calvello et al. - 2022 - Ensemble Kalman Methods A Mean Field Perspective.pdf:application/pdf},
}

@misc{carrillo2024mean,
      title={The Mean Field Ensemble Kalman Filter: Near-Gaussian Setting}, 
      author={J. A. Carrillo and F. Hoffmann and A. M. Stuart and U. Vaes},
      year={2024},
      eprint={2212.13239},
      archivePrefix={arXiv},
      primaryClass={math.OC}
}

@misc{carrillo2024statistical,
      title={Statistical Accuracy of Approximate Filtering Methods}, 
      author={J. A. Carrillo and F. Hoffmann and A. M. Stuart and U. Vaes},
      year={2024},
      eprint={2402.01593},
      archivePrefix={arXiv},
      primaryClass={math.NA}
}


@article{vetra2018,
author = {Sanita Vetra-Carvalho, Peter Jan van Leeuwen, Lars Nerger, Alexander Barth, M. Umer Altaf, Pierre Brasseur, Paul Kirchgessner and Jean-Marie Beckers},
title = {State-of-the-art stochastic data assimilation methods for high-dimensional non-Gaussian problems},
journal = {Tellus A: Dynamic Meteorology and Oceanography},
volume = {70},
number = {1},
pages = {1--43},
year = {2018},
publisher = {Taylor \& Francis},
doi = {10.1080/16000870.2018.1445364},
URL = {https://doi.org/10.1080/16000870.2018.1445364},
eprint = {https://doi.org/10.1080/16000870.2018.1445364},
abstract = { This paper compares several commonly used state-of-the-art ensemble-based data assimilation methods in a coherent mathematical notation. The study encompasses different methods that are applicable to high-dimensional geophysical systems, like ocean and atmosphere and provide an uncertainty estimate. Most variants of Ensemble Kalman Filters, Particle Filters and second-order exact methods are discussed, including Gaussian Mixture Filters, while methods that require an adjoint model or a tangent linear formulation of the model are excluded. The detailed description of all the methods in a mathematically coherent way provides both novices and experienced researchers with a unique overview and new insight in the workings and relative advantages of each method, theoretically and algorithmically, even leading to new filters. Furthermore, the practical implementation details of all ensemble and particle filter methods are discussed to show similarities and differences in the filters aiding the users in what to use when. Finally, pseudo-codes are provided for all of the methods presented in this paper. }
}