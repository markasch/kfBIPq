@book{Asch2016,
	address = {Philadelphia, PA},
	title = {Data {Assimilation}: {Methods}, {Algorithms}, and {Applications}},
	isbn = {978-1-61197-453-9 978-1-61197-454-6},
	shorttitle = {Data {Assimilation}},
	url = {http://epubs.siam.org/doi/book/10.1137/1.9781611974546},
	language = {en},
	urldate = {2024-01-03},
	publisher = {Society for Industrial and Applied Mathematics},
	author = {Asch, Mark and Bocquet, Marc and Nodet, Maëlle},
	month = dec,
	year = {2016},
	doi = {10.1137/1.9781611974546},
	file = {Available Version (via Google Scholar):/Users/markasch/Zotero/storage/63X2LMER/Asch et al. - 2016 - Data Assimilation Methods, Algorithms, and Applic.pdf:application/pdf},
}

@book{Asch2022,
	address = {Philadelphia, PA},
	title = {A {Toolbox} for {Digital} {Twins}: {From} {Model}-{Based} to {Data}-{Driven}},
	isbn = {978-1-61197-696-0 978-1-61197-697-7},
	shorttitle = {A {Toolbox} for {Digital} {Twins}},
	url = {https://epubs.siam.org/doi/book/10.1137/1.9781611976977},
	language = {en},
	urldate = {2024-01-03},
	publisher = {Society for Industrial and Applied Mathematics},
	author = {Asch, Mark},
	month = jan,
	year = {2022},
	doi = {10.1137/1.9781611976977},
	file = {Available Version (via Google Scholar):/Users/markasch/Zotero/storage/I9SHUNXY/Asch - 2022 - A Toolbox for Digital Twins From Model-Based to D.pdf:application/pdf},
}

@Book{Sarkka2023,
  author    = {S{\"a}rkk{\"a}, S. and Svensson, L.},
  publisher = {Cambridge University Press},
  title     = {Bayesian Filtering and Smoothing},
  year      = {2023},
}


@book{LSZ2015,
	address = {Cham},
	series = {Texts in {Applied} {Mathematics}},
	title = {Data {Assimilation}: {A} {Mathematical} {Introduction}},
	volume = {62},
	isbn = {978-3-319-20324-9 978-3-319-20325-6},
	shorttitle = {Data {Assimilation}},
	url = {https://link.springer.com/10.1007/978-3-319-20325-6},
	language = {en},
	urldate = {2024-02-29},
	publisher = {Springer International Publishing},
	author = {Law, Kody and Stuart, Andrew and Zygalakis, Konstantinos},
	year = {2015},
	doi = {10.1007/978-3-319-20325-6},
	file = {Law et al. - 2015 - Data Assimilation A Mathematical Introduction.pdf:/Users/markasch/Zotero/storage/KD4VDZAD/Law et al. - 2015 - Data Assimilation A Mathematical Introduction.pdf:application/pdf},
}


@misc{Huang2022,
	title = {Efficient {Derivative}-free {Bayesian} {Inference} for {Large}-{Scale} {Inverse} {Problems}},
	url = {http://arxiv.org/abs/2204.04386},
	abstract = {We consider Bayesian inference for large scale inverse problems, where computational challenges arise from the need for repeated evaluations of an expensive forward model. This renders most Markov chain Monte Carlo approaches infeasible, since they typically require \$O(10{\textasciicircum}4)\$ model runs, or more. Moreover, the forward model is often given as a black box or is impractical to differentiate. Therefore derivative-free algorithms are highly desirable. We propose a framework, which is built on Kalman methodology, to efficiently perform Bayesian inference in such inverse problems. The basic method is based on an approximation of the filtering distribution of a novel mean-field dynamical system into which the inverse problem is embedded as an observation operator. Theoretical properties of the mean-field model are established for linear inverse problems, demonstrating that the desired Bayesian posterior is given by the steady state of the law of the filtering distribution of the mean-field dynamical system, and proving exponential convergence to it. This suggests that, for nonlinear problems which are close to Gaussian, sequentially computing this law provides the basis for efficient iterative methods to approximate the Bayesian posterior. Ensemble methods are applied to obtain interacting particle system approximations of the filtering distribution of the mean-field model; and practical strategies to further reduce the computational and memory cost of the methodology are presented, including low-rank approximation and a bi-fidelity approach. The effectiveness of the framework is demonstrated in several numerical experiments, including proof-of-concept linear/nonlinear examples and two large-scale applications: learning of permeability parameters in subsurface flow; and learning subgrid-scale parameters in a global climate model from time-averaged statistics.},
	language = {en},
	urldate = {2024-01-03},
	publisher = {arXiv},
	author = {Huang, Daniel Zhengyu and Huang, Jiaoyang and Reich, Sebastian and Stuart, Andrew M.},
	month = aug,
	year = {2022},
	note = {arXiv:2204.04386 [cs, math]},
	keywords = {Mathematics - Numerical Analysis},
	file = {Huang et al. - 2022 - Efficient Derivative-free Bayesian Inference for L.pdf:/Users/markasch/Zotero/storage/D29DHZW8/Huang et al. - 2022 - Efficient Derivative-free Bayesian Inference for L.pdf:application/pdf},
}



@incollection{Stuart2015,
	address = {Cham},
	title = {The {Bayesian} {Approach} to {Inverse} {Problems}},
	isbn = {978-3-319-11259-6},
	url = {https://link.springer.com/10.1007/978-3-319-11259-6_7-1},
	abstract = {These lecture notes highlight the mathematical and computational structure relating to the formulation of, and development of algorithms for, the Bayesian approach to inverse problems in differential equations. This approach is fundamental in the quantiﬁcation of uncertainty within applications involving the blending of mathematical models with data. The ﬁnite-dimensional situation is described ﬁrst, along with some motivational examples. Then the development of probability measures on separable Banach space is undertaken, using a random series over an inﬁnite set of functions to construct draws; these probability measures are used as priors in the Bayesian approach to inverse problems. Regularity of draws from the priors is studied in the natural Sobolev or Besov spaces implied by the choice of functions in the random series construction, and the Kolmogorov continuity theorem is used to extend regularity considerations to the space of Hölder continuous functions. Bayes’ theorem is derived in this prior setting, and here interpreted as ﬁnding conditions under which the posterior is absolutely continuous with respect to the prior, and determining a formula for the Radon-Nikodym derivative in terms of the likelihood of the data. Having established the form of the posterior, we then describe various properties common to it in the inﬁnite-dimensional setting. These properties include well-posedness, approximation theory, and the existence of maximum a posteriori estimators. We then describe measure-preserving dynamics, again on the inﬁnite-dimensional space, including Markov chain Monte Carlo and sequential Monte Carlo methods, and measure-preserving reversible stochastic differential equations. By formulating the theory and algorithms on the underlying inﬁnite-dimensional space, we obtain a framework suitable for rigorous analysis of the accuracy of reconstructions, of computational complexity, as well as naturally constructing algorithms which perform well under mesh reﬁnement, since they are inherently well deﬁned in inﬁnite dimensions.},
	language = {en},
	urldate = {2024-01-08},
	booktitle = {Handbook of {Uncertainty} {Quantification}},
	publisher = {Springer International Publishing},
	author = {Dashti, Masoumeh and Stuart, Andrew M.},
	editor = {Ghanem, Roger and Higdon, David and Owhadi, Houman},
	year = {2015},
	doi = {10.1007/978-3-319-11259-6_7-1},
	keywords = {Inverse Problem, BIP, Bayes},
	pages = {1--118},
	file = {Dashti and Stuart - 2015 - The Bayesian Approach to Inverse Problems.pdf:/Users/markasch/Zotero/storage/BNJ6LD8D/Dashti and Stuart - 2015 - The Bayesian Approach to Inverse Problems.pdf:application/pdf},
}


@article{Stuart2013,
	title = {Ensemble {Kalman} methods for inverse problems},
	volume = {29},
	issn = {0266-5611, 1361-6420},
	url = {https://iopscience.iop.org/article/10.1088/0266-5611/29/4/045001},
	doi = {10.1088/0266-5611/29/4/045001},
	abstract = {The ensemble Kalman ﬁlter (EnKF) was introduced by Evensen in 1994 (Evensen 1994 J. Geophys. Res. 99 10143–62) as a novel method for data assimilation: state estimation for noisily observed time-dependent problems. Since that time it has had enormous impact in many application domains because of its robustness and ease of implementation, and numerical evidence of its accuracy. In this paper we propose the application of an iterative ensemble Kalman method for the solution of a wide class of inverse problems. In this context we show that the estimate of the unknown function that we obtain with the ensemble Kalman method lies in a subspace A spanned by the initial ensemble. Hence the resulting error may be bounded above by the error found from the best approximation in this subspace. We provide numerical experiments which compare the error incurred by the ensemble Kalman method for inverse problems with the error of the best approximation in A, and with variants on traditional least-squares approaches, restricted to the subspace A. In so doing we demonstrate that the ensemble Kalman method for inverse problems provides a derivative-free optimization method with comparable accuracy to that achieved by traditional least-squares approaches. Furthermore, we also demonstrate that the accuracy is of the same order of magnitude as that achieved by the best approximation. Three examples are used to demonstrate these assertions: inversion of a compact linear operator; inversion of piezometric head to determine hydraulic conductivity in a Darcy model of groundwater ﬂow; and inversion of Eulerian velocity measurements at positive times to determine the initial condition in an incompressible ﬂuid.},
	language = {en},
	number = {4},
	urldate = {2024-01-03},
	journal = {Inverse Problems},
	author = {Iglesias, Marco A and Law, Kody J H and Stuart, Andrew M},
	month = apr,
	year = {2013},
	keywords = {EnKF, EKI},
	pages = {045001},
	file = {Iglesias et al. - 2013 - Ensemble Kalman methods for inverse problems.pdf:/Users/markasch/Zotero/storage/GMPYK7JW/Iglesias et al. - 2013 - Ensemble Kalman methods for inverse problems.pdf:application/pdf},
}

@misc{Stuart2022,
	title = {Ensemble {Kalman} {Methods}: {A} {Mean} {Field} {Perspective}},
	shorttitle = {Ensemble {Kalman} {Methods}},
	url = {http://arxiv.org/abs/2209.11371},
	abstract = {This paper provides a unifying mean ﬁeld based framework for the derivation and analysis of ensemble Kalman methods. Both state estimation and parameter estimation problems are considered, and formulations in both discrete and continuous time are employed. For state estimation problems both the control and ﬁltering approaches are studied; analogously, for parameter estimation (inverse) problems the optimization and Bayesian perspectives are both studied. The approach taken uniﬁes a wide-ranging literature in the ﬁeld, provides a framework for analysis of ensemble Kalman methods, and suggests open problems.},
	language = {en},
	urldate = {2024-01-03},
	publisher = {arXiv},
	author = {Calvello, Edoardo and Reich, Sebastian and Stuart, Andrew M.},
	month = sep,
	year = {2022},
	note = {arXiv:2209.11371 [cs, math]},
	keywords = {Mathematics - Numerical Analysis, Mathematics - Optimization and Control, EnKF, EKI, mean field},
	file = {Calvello et al. - 2022 - Ensemble Kalman Methods A Mean Field Perspective.pdf:/Users/markasch/Zotero/storage/HB5SG9SH/Calvello et al. - 2022 - Ensemble Kalman Methods A Mean Field Perspective.pdf:application/pdf},
}
